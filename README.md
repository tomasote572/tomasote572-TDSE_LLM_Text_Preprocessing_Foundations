# TDSE_LLM_Text_Preprocessing_Foundations

## Embeddings y Preprocesamiento de Texto para LLMs

Este repositorio contiene un notebook Jupyter educativo basado en el CapÃ­tulo 2 del libro "Build a Large Language Model (From Scratch)" de Sebastian Raschka.

### Contenido

#### ğŸ““ `embeddings.ipynb`
Notebook completo que cubre los fundamentos del preprocesamiento de texto para Large Language Models:

1. **TokenizaciÃ³n bÃ¡sica y Byte Pair Encoding (BPE)**
   - ConversiÃ³n de texto a tokens
   - ImplementaciÃ³n con tiktoken (GPT-2)
   
2. **Data sampling con sliding window**
   - CreaciÃ³n de ventanas de entrenamiento
   - ParÃ¡metros `max_length` y `stride`
   
3. **Token embeddings**
   - Representaciones vectoriales de tokens
   - Matrices de embeddings aprendibles
   
4. **Positional encodings**
   - IncorporaciÃ³n de informaciÃ³n de posiciÃ³n
   - Encodings absolutos y relativos

5. **Experimento: Efecto de max_length y stride**
   - AnÃ¡lisis prÃ¡ctico de parÃ¡metros
   - VisualizaciÃ³n de resultados

#### ğŸ“„ `the-verdict.txt`
Archivo de texto de ejemplo usado en el notebook para demostraciÃ³n.

### CaracterÃ­sticas especiales

- âœ… **4 explicaciones en espaÃ±ol** que responden preguntas fundamentales:
  - Â¿Por quÃ© necesitamos tokenizaciÃ³n?
  - Â¿Por quÃ© usar sliding window para crear muestras?
  - Â¿Por quÃ© los embeddings codifican significado?
  - Â¿Por quÃ© necesitamos positional encodings?

- âœ… **Experimento prÃ¡ctico** con anÃ¡lisis de parÃ¡metros de data sampling

- âœ… **148 celdas totales** (94 markdown, 54 cÃ³digo)

- âœ… **CÃ³digo ejecutable** de principio a fin

### Requisitos

```bash
pip install torch tiktoken pandas jupyter
```

### Uso

```bash
jupyter notebook embeddings.ipynb
```

### Estructura del notebook

```
IntroducciÃ³n
â”œâ”€â”€ ExplicaciÃ³n 1: TokenizaciÃ³n (con cÃ³digo)
â”œâ”€â”€ ExplicaciÃ³n 2: Sliding Window (con cÃ³digo)
â”œâ”€â”€ ExplicaciÃ³n 3: Embeddings (con cÃ³digo)
â”œâ”€â”€ ExplicaciÃ³n 4: Positional Encodings (con cÃ³digo)
â””â”€â”€ Experimento: max_length y stride (con anÃ¡lisis)
```

### Referencias

- Libro: "Build a Large Language Model (From Scratch)" - Sebastian Raschka
- Repositorio original: https://github.com/rasbt/LLMs-from-scratch
- CapÃ­tulo 2: https://github.com/rasbt/LLMs-from-scratch/tree/main/ch02

### Licencia

Este material educativo estÃ¡ basado en cÃ³digo de fuente abierta del repositorio LLMs-from-scratch.